# Awesome Eye Tracking Research [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of research papers, datasets, and resources in the field of eye tracking, with a focus on visual search applications.
Contributions are always welcome!

---

## 2025

### Artificial Intelligence in Medicine
* ItpCtrl-AI: End-to-end interpretable and controllable artificial intelligence by modeling radiologistsâ€™ intentions [[paper]](https://www.sciencedirect.com/science/article/abs/pii/S0933365724002963) [[code]](https://github.com/UARK-AICV/ItpCtrl-AI)

### WACV
* GazeSearch: Radiology Findings Search Benchmark [[paper]](https://openaccess.thecvf.com/content/WACV2025/papers/Pham_GazeSearch_Radiology_Findings_Search_Benchmark_WACV_2025_paper.pdf) [[code]](https://github.com/UARK-AICV/GazeSearch)
---

## 2024

### NeurIPS
* Eye-Gaze Guided Multi-modal Alignment for Medical Representation Learning [[paper]](https://proceedings.neurips.cc/paper_files/paper/2024/hash/0b9536e186a77feff516893a5f393f7a-Abstract-Conference.html) [[code]](https://github.com/MoMarky/EGMA)
* UniAR: Unifying Human Attention and Response Prediction on Visual Content [[paper]](https://arxiv.org/abs/2312.10175) [code unavailable]
### AAAI
* Mining gaze for contrastive learning toward computer-assisted diagnosis [[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/28586) [[code]](https://github.com/zhaozh10/McGIP)

### ACCV
* FG-CXR: A Radiologist-Aligned Gaze Dataset for Enhancing Interpretability in Chest X-Ray Report Generation [[paper]](https://link.springer.com/chapter/10.1007/978-981-96-0960-4_5) [[code]](https://github.com/UARK-AICV/FG-CXR)

### CVPR
* Unifying Top-down and Bottom-up Scanpath Prediction Using Transformers [[paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Yang_Unifying_Top-down_and_Bottom-up_Scanpath_Prediction_Using_Transformers_CVPR_2024_paper.html) [[code]](https://github.com/cvlab-stonybrook/HAT)
* Beyond Average: Individualized Visual Scanpath Prediction [[paper]](https://openaccess.thecvf.com/content/CVPR2024/html/Chen_Beyond_Average_Individualized_Visual_Scanpath_Prediction_CVPR_2024_paper.html) [[code]](https://github.com/chenxy99/IndividualScanpath)

### European Journal of Radiology
* Shedding light on ai in radiology: A systematic review and taxonomy of eye gaze-driven interpretability in deep learning [[paper]](https://www.sciencedirect.com/science/article/pii/S0720048X24000573) [code unavailable]

### IEEE JBHI
* Eye gaze guided cross-modal alignment network for radiology report generation [[paper]](https://ieeexplore.ieee.org/document/10596697/) [code unavailable]
* The Use of Machine Learning in Eye Tracking Studies in Medical Imaging: A Review [[paper]](https://pubmed.ncbi.nlm.nih.gov/38421842/) [code unavailable]

### IEEE T-IM
* Artificially Generated Visual Scanpath Improves Multi-label Thoracic Disease Classification in Chest X-Ray Images [[paper]](https://ieeexplore.ieee.org/document/10599335) [code unavailable]

### Machine Learning and Knowledge Extraction
* EyeXNet: Enhancing Abnormality Detection and Diagnosis via Eye-Tracking and X-ray Fusion [[paper]](https://www.mdpi.com/2504-4990/6/2/48) [code unavailable]

### NPJ Digital Medicine
* Expert gaze as a usability indicator of medical AI decision support systems: a preliminary study [[paper]](https://www.nature.com/articles/s41746-024-01192-8) [code unavailable]

### WACV
* I-AI: A Controllable & Interpretable AI System for Decoding Radiologists' Intense Focus for Accurate CXR Diagnoses [[paper]](https://openaccess.thecvf.com/content/WACV2024/html/Pham_I-AI_A_Controllable__Interpretable_AI_System_for_Decoding_Radiologists_WACV_2024_paper.html) [[code]](https://github.com/UARK-AICV/IAI)
* Gazegnn: A gaze-guided graph neural network for chest x-ray classification [[paper]](https://openaccess.thecvf.com/content/WACV2024/html/Wang_GazeGNN_A_Gaze-Guided_Graph_Neural_Network_for_Chest_X-ray_Classification_WACV_2024_paper.html) [[code]](https://github.com/ukaukaaaa/GazeGNN)

---

## 2023

### ACM Symposium on Spatial User Interaction
* Simulating Human Visual System Based on Vision Transformer [[paper]](https://dl.acm.org/doi/10.1145/3607822.3616408) [code unavailable]

### CHI
* UEyes: Understanding Visual Saliency across User Interface Types [[paper]](https://dl.acm.org/doi/10.1145/3544548.3581096) [[code]](https://github.com/YueJiang-nj/UEyes-CHI2023)

### CVPR
* Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention [[paper]](https://openaccess.thecvf.com/content/CVPR2023/html/Mondal_Gazeformer_Scalable_Effective_and_Fast_Prediction_of_Goal-Directed_Human_CVPR_2023_paper.html) [[code]](https://github.com/cvlab-stonybrook/Gazeformer)

### IEEE TMI
* Eye-Gaze-Guided Vision Transformer for Rectifying Shortcut Learning [[paper]](https://pubmed.ncbi.nlm.nih.gov/37335796/) [[code]](https://github.com/MoMarky/Eye-gaze-Guided-Vision-Transformer)

---

## 2022

### CVPRW
* Scanpathnet: A recurrent mixture density network for scanpath prediction [[paper]](https://www.computer.org/csdl/proceedings-article/cvprw/2022/873900f006/1G574odZPjO) [code unavailable]

### ECCV
* Target-absent Human Attention [[paper]](https://www.ecva.net/papers/eccv_2022/papers_ECCV/html/361_ECCV_2022_paper.php) [[code]](https://github.com/cvlab-stonybrook/Target-absent-Human-Attention)

### IEEE TMI
* Follow my eye: Using gaze to supervise computer-aided diagnosis [[paper]](https://ieeexplore.ieee.org/abstract/document/9675204/) [code unavailable]

### Journal of Vision
* DeepGaze III: Modeling free-viewing human scanpaths with deep learning. [[paper]](https://jov.arvojournals.org/article.aspx?articleid=2779261) [[code]](https://github.com/matthias-k/DeepGaze)

### MICCAI
* Gazeradar: A gaze and radiomics-guided disease localization framework [[paper]](https://link.springer.com/chapter/10.1007/978-3-031-16443-9_66) [[code]](https://github.com/bmi-imaginelab/gazeradar)

### Scientific Data
* REFLACX, a dataset of reports and eye-tracking data for localization of abnormalities in chest x-rays [[paper]](https://www.nature.com/articles/s41597-022-01453-9) [[code]](https://github.com/ricbl/eyetracking)
---

## 2021

### IJCAI
* Leveraging Human Attention in Novel Object Captioning [[paper]](https://www.ijcai.org/proceedings/2021/86) [code unavailable]

### Scientific Data
* Creation and validation of a chest X-ray dataset with eye-tracking and report dictation for AI development [[paper]](https://www.nature.com/articles/s41597-021-00863-5) [[code]](https://github.com/cxr-eye-gaze/eye-gaze-dataset)

---

## 2020

### CVPR
* Predicting Goal-directed Human Attention Using Inverse Reinforcement Learning [[paper]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Predicting_Goal-Directed_Human_Attention_Using_Inverse_Reinforcement_Learning_CVPR_2020_paper.pdf) [[code]](https://github.com/cvlab-stonybrook/Scanpath_Prediction)

### ECCV
* AiR: Attention with Reasoning Capability [[paper]](https://www-users.cse.umn.edu/~qzhao/air.html) [[code]](https://github.com/szzexpoi/AiR)

---

## 2019

### CVPRW
* Benchmarking Gaze Prediction for Categorical Visual Search [[paper]](https://www3.cs.stonybrook.edu/~minhhoai/papers/Gaze_Benchmark_CVPRW19.pdf) [code unavailable]

### IEEE TPAMI
* Visual Scanpath Prediction using IOR-ROI Recurrent Mixture Density Network [[paper]](https://ieeexplore.ieee.org/document/8918321) [[code]](https://github.com/sunwj/scanpath)

### Medical Image Analysis
* A collaborative computer aided diagnosis (C-CAD) system with eye-tracking, sparse attentional model, and deep learning [[paper]](https://pubmed.ncbi.nlm.nih.gov/30399507/) [code unavailable]

### MMSys
* A Dataset of Eye Movements for the Children with Autism Spectrum Disorder [[paper]](https://dl.acm.org/doi/10.1145/3304109.3325818) [code unavailable]

---

## 2018

### CVPR
* Active Fixation Control to Predict Saccade Sequences [[paper]](https://openaccess.thecvf.com/content_cvpr_2018/html/Wloka_Active_Fixation_Control_CVPR_2018_paper.html) [[code]](https://github.com/TsotsosLab/STAR-FC) [[python]](https://github.com/ykotseruba/pySTAR-FC)

### ECCV
* Boosted Attention: Leveraging Human Attention for Image Captioning [[paper]](https://openaccess.thecvf.com/content_ECCV_2018/papers/Shi_Chen_Boosted_Attention_Leveraging_ECCV_2018_paper.pdf) [[arXiv]](https://arxiv.org/abs/1904.00767) [code unavailable]

### IEEE TIP
* Predicting Human Eye Fixations via an LSTM-based Saliency Attentive Model [[paper]](https://ieeexplore.ieee.org/document/8400593/) [[arXiv]](https://arxiv.org/abs/1611.09571) [[code]](https://github.com/marcellacornia/sam)
---

## 2016

### arXiv
* DeepGaze II: Reading fixations from deep features trained on object recognition. [[paper]](https://arxiv.org/abs/1610.01563) [[code]](https://github.com/matthias-k/DeepGaze) [[tensorflow]](https://github.com/Po-Hsuan-Huang/Deep-Gaze-2)
* Seeing with Humans: Gaze-Assisted Neural Image Captioning [[paper]](https://arxiv.org/abs/1608.05203) [code unavailable]

---

## 2015

### CVPR
* SALICON: Saliency in Context [[paper]](http://salicon.net) [[code]](https://github.com/NUS-VIP/salicon-api)

### ICME
* PET: An eye-tracking dataset for animal-centric Pascal object classes [[paper]](https://stefan.winkler.site/Publications/icme2015.pdf) [code unavailable]

### Neuron
* Atypical Visual Saliency in Autism Spectrum Disorder Quantified through Model-Based Eye Tracking [[paper]](https://pmc.ncbi.nlm.nih.gov/articles/PMC4662072/) [code unavailable]

### Vision Research
* Saccadic model of eye movements for free-viewing condition [[paper]](https://www.sciencedirect.com/science/article/pii/S0042698915000504) [code unavailable]

---

## 2014

### ECCV
* Training object class detectors from eye tracking data [[paper]](https://calvin-vision.net/bigstuff/Publications/papadopouloseccv14.pdf) [code unavailable]

### Journal of Vision
* Predicting human gaze beyond pixels [[paper]](https://jov.arvojournals.org/article.aspx?articleid=2193943) [[code]](https://github.com/NUS-VIP/predicting-human-gaze-beyond-pixels)

---

## 2013

### Psychological Science
* The invisible gorilla strikes again: Sustained inattentional blindness in expert observers [[paper]](https://pmc.ncbi.nlm.nih.gov/articles/PMC3964612/) [code unavailable]

### Journal of Vision
* Scanners and Drillers: Characterizing Expert Visual Search through Volumetric Images [[paper]](https://pubmed.ncbi.nlm.nih.gov/23922445/) [[code]](https://github.com/olwal/gaze3d_matlab)

---

## 2011

### CVPR
* Simulating human saccadic scanpaths on natural images [[paper]](https://cognn.com/papers/30%20CVPR%202011%20Wei%20Simulating%20Human%20Saccadic%20Scanpath%20on%20Natural%20Images.pdf) [code unavailable]

---

## 2009

### Visual Cognition
* Modelling search for people in 900 scenes: A combined source model of eye guidance [[paper]](https://pmc.ncbi.nlm.nih.gov/articles/PMC2790194/) [code unavailable]

---

## 2007

### Radiology
* Holistic component of image perception in mammogram interpretation: gaze-tracking study [[paper]](https://pubmed.ncbi.nlm.nih.gov/17255410/) [code unavailable]

---

## 1998

### IEEE TPAMI
* A model of saliency-based visual attention for rapid scene analysis [[paper]](https://ieeexplore.ieee.org/document/730558) [code unavailable]
